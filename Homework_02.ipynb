{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"Homework_02.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 02:  Linear Regression in Theory and Practice\n",
    "\n",
    "In this homework, you will learn how to **create** and **explore** a simple, synthetic regression dataset using scikit‚Äêlearn‚Äôs `make_regression` function. We often use synthetic data to **test out** our modeling workflows, gain **hands‚Äêon experience** with linear regression, and observe how **noise**, **training set size**, and other factors affect model performance. By controlling the dataset generation, you can see precisely how well the model recovers known parameters, and you‚Äôll practice splitting data into training and testing sets to measure **Mean Squared Error (MSE)**. This will give you insight into how regression models behave under different conditions (such as varying amounts of training data) and help you interpret the resulting errors and comparisons.\n",
    "\n",
    "In some problems you will need to do a bit of research in `sklearn`'s documentation. The functions we are using are very common in ML, and it will be well worth the time you spend reading through the documentation and looking at the examples provided there. \n",
    "\n",
    "As I mentioned in the Live Session, some things I will ask you do to are not graded; I expect you to do them just as thoroughly as the answers which will be graded.  To skip the non-graded parts\n",
    "and just focus on the graded portions will waste your time and money, and result in a less-than-expected return on both when you work on projects and proceed to later modules, and, eventually, to a career in data science. \n",
    "\n",
    "#### One more things before you start:  \n",
    "\n",
    "This is the last homework in which you will get instant feedback on your solutions; since Gradescope is not set up for this, we have used the Otter auto-grader to allow immediate feedback in this notebook. After each cell in which you assign a value to a variable such as a1a etc. there is a cell which will check your solution. Therefore, you may test your solutions as much as you wish before submitting to Gradescope. Starting with HW 03, you will receive your grades only after the late period is over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful imports and utilities\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import kagglehub\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import fetch_california_housing,make_regression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from math import isclose\n",
    "\n",
    "# globals\n",
    "\n",
    "random_state = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem One:  Generate and Display a Simple Univariant Regression Dataset\n",
    "\n",
    "In this first problem, we are going to experiment with `sklearn`'s `make_regression` function, which can generate synthetic datasets with various characteristics, including the number of samples, the standard deviation of the errors, and many other useful parameters. (Oddly, it makes you choose the bias, and it randomly chooses the other coefficients; it also does not allow you to specify the range of the features -- however, it would be easy to write your own version which does these things.)\n",
    "\n",
    "\n",
    "Using `make_regression` is a common way to test out frameworks and investigate the properties of models. \n",
    "\n",
    "\n",
    "Before you start, read through the `sklearn` documentation on `make_regression`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A\n",
    "\n",
    "Generate a univariate dataset $X, y$ with\n",
    "   - 20 samples\n",
    "   - error standard deviation of 20 (called `noise` in the function)\n",
    "   - y-intercept of 0.5 (called `bias` in the function)\n",
    "   - `random_state = 42`\n",
    "   - `coef = True`  (this will return the coefficients of the underlying model)\n",
    "   \n",
    "This will return a tuple with 3 values (read the docs!). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "- Set `a1b` to the range of X, i.e., an array [lb,ub] (or list or tuple) where lb is the smallest value in X and ub is the largest, rounded to 4 decimal places\n",
    "- Note: You can use `np.around(...)` for just about anything, including floats and tuples.  For numpy arrays, generally it is more readable to use the postfix version  `.round(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Your code here\n",
    "\n",
    "a1b = ...\n",
    "\n",
    "print(f'Range of X = {a1b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C\n",
    "\n",
    "- Set `a1c` to the slope of the underlying model, to 4 decimal places. \n",
    "\n",
    "- Hint: `make_regression` will return the coefficients as an array with one fewer dimensions than X; in this case, it is a 0-dimension array whose shape is `()`.  Weird, and you won't typically see this.  You can pretend it is just a float. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Your code here\n",
    "\n",
    "a1c = ...\n",
    "\n",
    "print(f'Slope = {a1c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D\n",
    "\n",
    "Generate a scatterplot of the dataset with the following:\n",
    "   - A suitable title\n",
    "   - Figure size of (8,6)\n",
    "   - Suitable labels on x and y axis (just X and y are fine)\n",
    "   - The underlying model (with no noise), a line extending through the range of X, using `color=grey`\n",
    "   - A label \"Underlying Model\" on the line representing the model and a label \"Data Points\" on\n",
    "     the sample points. (Don't forget to call `plt.legend()` to show the labels!)\n",
    "\n",
    "Note: Optional, but playing around with the style of the scatter points will produce a better-looking plot; I use `marker='.'` to get smaller dots for a scatterplot; you can\n",
    "also play around with `linestyle='--'` or other choices, plus of course colors, saturation `alpha`, etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Two: Run Linear Regression on the Data Set and Evaluate the Results\n",
    "\n",
    "Now we will use `sklearn`'s `LinearRegression` model to create a model from the dataset. Of course, the **underlying model** has already been\n",
    "created, but your linear regression won't know that, and it has to determine the best model given the data samples it is given.\n",
    "\n",
    "### Part A: Create and Evaluate a Linear Model\n",
    "- Create a linear regression model and train it on X,y. \n",
    "- Set `a2a` to the bias/y-intercept of the model, to 4 decimal places            \n",
    "- NOTE:  You must round the value assigned to `a2a`, NOT just print it out with 4 digits of precision.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Your code here\n",
    "\n",
    "a2a = ...\n",
    "\n",
    "print(f'Bias = {a2a}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "- Set `a2b` to the slope of the model.\n",
    "- Hint: The coefficients are returned as a 1-dimensional array (unlike make_regression!), so you'll need to turn a 1-element array into a scalar. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "a2b = ...\n",
    "\n",
    "print(f'Slope = {a2b}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C\n",
    "\n",
    "- Set `a2c` to the training MSE of the model on the dataset, to 4 decimal places\n",
    "- Hint: generate an array 1y_pred1 by using the model to predict the targets fromd the original X, then calculate the mean squared error using the appropriate `sklearn` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Your code here\n",
    "\n",
    "a2c = ...\n",
    "\n",
    "print(f'Training MSE = {a2c}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D\n",
    "\n",
    "- Set `a2d` to the coefficient of determination (R2) of the model (read the docs!), to 4 decimal places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Your code here\n",
    "\n",
    "a2d = ...\n",
    "\n",
    "print(f'Training R^2 Score = {a2d}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part E\n",
    "\n",
    "- Provide a visualization of the regression line by cutting and pasting the code from Problem One D, then adding a plot of the model's regression line in red. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pause and Ponder (no need to write answers, just think about these):  \n",
    "- Why does the linear regression line not match the underlying model?\n",
    "- Which parameters (bias, n_samples,noise) do you think affect how well the regression model matches the actual model?\n",
    "- What changes to the parameters would result in a more accurate match between underlying and regression models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Three:  How well does it generalize?\n",
    "\n",
    "The **most important issue** in making useful models is to ensure that they are able to **generalize to new data from the same domain.**  For example, if you create a model from a housing price dataset, \n",
    "you want it to be able to predict what price could be obtained if you build new houses with particular features. You will learn techniques for judging how well models generalize in\n",
    "the next few lessons, and it will continue to be a concern in building any machine learning model. \n",
    "\n",
    "For now, since we have the underlying model (which never happens IRL!) we can easily create new data samples with the same characteristics as the set we used for training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A\n",
    "\n",
    "- Complete the following stub to create a function to create new points to add the data set, with all the same parameters as the underlying model, following these steps:\n",
    "    1. Create a random number within the existing range of X, using `np.random.uniform` \n",
    "    2. Use the bias and slope of the underlying model to find the point (x,y) on the regression line (which is the prediction for y given x)\n",
    "    3. Return (x,y)\n",
    "\n",
    "- Test it by running the cell repeatedly to see the results (we are not setting a random seed, so it will generate random answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_sample():\n",
    "    # Your code here\n",
    "    return ...\n",
    "\n",
    "generate_sample()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "- Generate 5 new data points (we'll use these below to represent new data not yet seen) and assign them to ndarrays `X_new` and `y_new`, \n",
    "- Hint: create a list of pairs and split using zip(* ...)\n",
    "\n",
    "- Set `a3b` to the first 2 values in `X_new`, rounded to 4 decimal plac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(42)             # do not remove this line!\n",
    "\n",
    "# Your code here\n",
    "\n",
    "a3b = ...\n",
    "\n",
    "print(a3b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C\n",
    "\n",
    "- Cut and paste the code from Problem Two E and add one line of code to display the new data points in green, in addition to the original data and the two lines representing the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D\n",
    "\n",
    "- Assign the MSE on the new data to ans1a3(we'll later call this the \"test MSE\") , rounded to 4 decimal points\n",
    "- Hint: When you \"roll your own\" datasets using ndarrays, you will generally have to reshape them using `.reshape(-1,1)` because sklearn models expect a column array, not an 1D array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "a3d = ...\n",
    "\n",
    "print(f'MSE on new data = {a3d}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part E:  Let's Compare Metrics\n",
    "\n",
    "We now have three related values:\n",
    "- Noise = standard deviation of underlying model \n",
    "- Training MSE of the linear model on the original data \n",
    "- Testing MSE of the linear model on new data \n",
    "\n",
    "Answer the following multiple-choice problems by assigning the variable to the  **most accurate** statement.\n",
    "\n",
    "#### E1) Comparing the Two MSEs\n",
    "\n",
    "Why might the training MSE be *larger* than the testing MSE in this scenario?\n",
    "\n",
    "1. These should be exactly the same, so there must have been an error somewhere.  \n",
    "2.  With only 25 training points, a few unusual data points (outliers) can increase the average training error; meanwhile, the small test set of 5 points could *by chance* lead to smaller errors overall.  \n",
    "3. There is always a positive bias in the regression line, so it will always be larger. \n",
    "4.  There is very little relationship between these two numbers, so the fact that they are close to each other must be an accident.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "a3e1 =  ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3e1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E2) Understanding the Noise Parameter\n",
    "\n",
    "Which statement best captures the significance of a noise standard deviation of 20 for interpreting the MSE?\n",
    "\n",
    "1. Since MSE is a measure of *variance* of the errors, and noise is a measure of *standard deviation*, an MSE of about $20^2 = 400$ reflects the irreducible noise in the data; in other words, no model can do much better than this on average.  \n",
    "2.  A noise standard deviation of 20 implies that we can, with enough data, reduce the MSE to 0.  \n",
    "3. MSE measures the *average* of absolute errors, so having \\(\\sigma = 20\\) implies our MSE should always be 20.  \n",
    "4. If the noise is 20, then with enough effort, we can create a model whose training and testing MSEs are *exactly* equal to 400.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "a3e2 =  ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3e2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E3) The Role of Dataset Size\n",
    "\n",
    "You fitted a linear model on **25** training points and tested it on **5** new points, both drawn from a process with noise standard deviation 20 (variance 400).  \n",
    "\n",
    "What would happen if we repeated the same experiment with more training/testing points or with even fewer points?  \n",
    "In other words, **how does dataset size affect the measured MSE values?**\n",
    "\n",
    "1.  If the training set is small, the MSE will always be *exactly* 400 for both training and test sets, since there‚Äôs too little data to deviate from the noise variance.  \n",
    "\n",
    "2.  Collecting more data actively *lowers* the true noise standard deviation from 20 to something smaller, guaranteeing an MSE below 400.  \n",
    "3. If you have fewer than 30 data points, the training MSE must always exceed 400 and the test MSE must always be *less* than 400.  \n",
    "4. Small sample sizes can cause large swings in MSE, sometimes pushing the training MSE above 400 while letting a tiny test set fall below 400 by chance. With larger datasets, the MSE typically stabilizes closer to 400.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "a3e3 =  ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3e3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Four: Linear Regression on an Actual Dataset (finally!)\n",
    "\n",
    "Let's consider applying what we have learned to an actual dataset, the Diabetes dataset from Kaggle. This has 10 features and 1 target,\n",
    "so it is an instance of **multiple regression**, however we can train a model almost exactly as we did in the univariate case. \n",
    "\n",
    "After doing a bit of EDA and massaging of the features, we will first consider separate regressions on several features of the dataset, and then run multiple regression on the whole set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Kaggle Diabetes Dataset\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "data_diabetes = load_diabetes(as_frame=True)\n",
    "df_diabetes = pd.concat([data_diabetes.data, data_diabetes.target.rename('DiseaseProgression')], axis=1)\n",
    "\n",
    "feature_names = df_diabetes.drop(columns=[\"DiseaseProgression\"]).columns.tolist()\n",
    "\n",
    "df_diabetes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diabetes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features of the Diabetes Dataset\n",
    "\n",
    "- **age**: age of the patient  \n",
    "- **sex**: gender of the patient  \n",
    "- **bmi**: body mass index (BMI)  \n",
    "- **bp**:  mean blood pressure  \n",
    "- **s1**:  measure of serum cholesterol levels  \n",
    "- **s2**:  measure related to low-density lipoproteins (LDL)  \n",
    "- **s3**:  measure of high-density lipoproteins (HDL)  \n",
    "- **s4**:  measure of total cholesterol-to-HDL ratio  \n",
    "- **s5**:  measure of serum triglycerides  \n",
    "- **s6**:  measure of blood sugar levels  \n",
    "- **DiseaseProgression**: Quantitative measure of diabetes disease progression one year after baseline (target variable)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one we'll give you:\n",
    "# Always useful to create histograms of the features when possible; the layout and formatting are sometimes awkward, so\n",
    "# I use the following:\n",
    "\n",
    "df_diabetes.hist(figsize=(12,8), layout=(3,4),grid=False,edgecolor='black')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A:\n",
    "\n",
    "- Generate the correlation matrix for all the features using Pandas' `.corr()` function, and plot it as a heatmap and give it an appropriate title.   \n",
    "- Hint: Use `seaborn`'s `heatmap` function, imported in the first cell as `sns`.  And have I mentioned you might want to read the docs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "- Now set `a4b` to the name of the feature which has the largest correlation with the target. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "a4b =  ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C\n",
    "\n",
    "- Next, in order to avoid any snickers when discussing the dataset, change the column name 'sex' to 'gender'\n",
    "  in place and set the variable `a4c` to a numpy array of the feature/column names.\n",
    "- Hint: if your answer starts `Index(...` then you have a Pandas data structure and not an ndarray as required. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "a4c = ...\n",
    "\n",
    "print(f'Feature names = {a4c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D\n",
    "\n",
    "- Create dataset in the form X,y from the dataframe by dropping the last column to create X, and just selecting the last column to make y\n",
    "\n",
    "- Note: `sklearn`'s models are perfectly happy to work with dataframes, so we can just keep them as such and not convert to ndarrays.  Two advantages are: you don't have to reshape for input to the model, and you keep the feature names in case you need them later.\n",
    "\n",
    "- Set `aa4d` to the pair  ( shape of X, shape of y )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "a4d = ...\n",
    "\n",
    "print(f'(shape of X, shape of y) = {a4d}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part E\n",
    "\n",
    "\n",
    "Now we will create two regression plots, the first for a univariate regression of just the most highly correlated feature, and\n",
    "then on the whole data set.  (We'll return to the issue of feature importance in later weeks.)\n",
    "\n",
    "- Create X_uni from X by selecting only the most highly correlated feature, and run a univariate regression with it against the target. \n",
    "- Assign `a4e` the \"training MSE\" by using the model to predict on X_uni and comparing the values with y. \n",
    "- As usual, round all floats to 4 decimal places.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "a4e = ...\n",
    "\n",
    "print(f'MSE on most correlated feature = {a4e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part F\n",
    "\n",
    "- Now run multiple regression on the entire X and assign the training MSE on X to `a4f`, rounded to 4 decimal places.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "a4f = ...\n",
    "\n",
    "print(f'MSE on whole set = {a4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part G: Testing for Generalization\n",
    "\n",
    "We will spend the next two lessons thinking about how to evaluate  models for generalization, but let's try a naive strategy\n",
    "for now:  We will split the dataset into training and testing sets, and see how the model performs on  data it has never seen.\n",
    "The disadvantage of this is that we have less training data, of course!\n",
    "\n",
    "- Use `sklearn`'s `train_test_split` to shuffle X and split it into 80% training data and 20% testing data with `random_state=42`\n",
    "- Train a model `model_training` on the training set, and then test it on the same set to find the training MSE. \n",
    "- Assign the training MSE to `a4g`, to... you guessed it... 4 decimal points.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "a4g = ...\n",
    "\n",
    "print(f'Training MSE = {a4g}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part H\n",
    "\n",
    "- Run the model created in Part G on the testing set and determine the test MSE \n",
    "- Set `a4h` to the test MSE, to 4 decimal points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "a4h = ...\n",
    "\n",
    "print(f'MSE on most correlated feature = {a4h}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I\n",
    "\n",
    "Now try setting the percentage of the test size to different values, perhaps 0.1, 0.2, 0.3, 0.4, and 0.5 and run the above\n",
    "cells and observe the training and testing MSEs. Then choose the best answer below. \n",
    "\n",
    "\n",
    "**How Does the Training‚ÄêSet Size Affect MSE?**\n",
    "\n",
    "1.  Both **training MSE** and **testing MSE** remain exactly the same regardless of how many points you use, provided you keep the `random_state` fixed.  \n",
    "2.  Both **training MSE** and **testing MSE** steadily converge to **zero** once you exceed a certain training‚Äêset size threshold (e.g., 30 points).  \n",
    "3.  **Training MSE** usually goes **up** slightly with a bigger training set (it‚Äôs harder to fit more points perfectly), but **testing MSE** tends to go **down** (the model generalizes better with more data).  \n",
    "4.  Both **training MSE** and **testing MSE** decrease when the training set grows, because the model memorizes a larger volume of data and thus reduces all errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "a4i = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part J\n",
    "\n",
    "How many hours did you spend completing this homework? Set `a4j` to a integer giving the answer to this question. Any answer will receive full credit in the autograder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "a4j = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4j</pre></strong> passed! üíØ</p>"
      ],
      "text/plain": [
       "q4j results: All test cases passed!"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4j\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1b": {
     "name": "q1b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2.5\n>>> hidden: True\n>>> # END TEST CONFIG\n>>> # HIDDEN\n>>> assert isclose(a1b[0],-1.9133, abs_tol=0.02) and isclose(a1b[1],1.5792, abs_tol=0.02)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2.5\n>>> hidden: True\n>>> # END TEST CONFIG\n>>> # HIDDEN\n>>> assert isclose(a1c,45.607, abs_tol=0.02)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2.5\n>>> hidden: True\n>>> # END TEST CONFIG\n>>> # HIDDEN\n>>> assert isclose(a2a,5.2857, abs_tol=0.02)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2b": {
     "name": "q2b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2.5\n>>> hidden: True\n>>> # END TEST CONFIG\n>>> # HIDDEN\n>>> assert isclose(a2b,45.7125, abs_tol=0.02)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2c": {
     "name": "q2c",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2.5\n>>> hidden: True\n>>> # END TEST CONFIG\n>>> # HIDDEN\n>>> assert isclose(a2c,436.913, abs_tol=0.02)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2d": {
     "name": "q2d",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2.5\n>>> hidden: True\n>>> # END TEST CONFIG\n>>> # HIDDEN\n>>> assert isclose(a2d,0.8072, abs_tol=0.02)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2.5\n>>> hidden: True\n>>> # END TEST CONFIG\n>>> # HIDDEN\n>>> assert isclose(a3b[0],-0.6052, abs_tol=0.02) and isclose(a3b[1],-1.3685, abs_tol=0.02)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3d": {
     "name": "q3d",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2.5\n>>> hidden: True\n>>> # END TEST CONFIG\n>>> # HIDDEN\n>>> assert isclose(a3d,245.9093, abs_tol=0.02)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3e1": {
     "name": "q3e1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2.5\n>>> hidden: True\n>>> # END TEST CONFIG\n>>> # HIDDEN\n>>> assert a3e1 == 2\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3e2": {
     "name": "q3e2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2.5\n>>> hidden: True\n>>> # END TEST CONFIG\n>>> # HIDDEN\n>>> assert a3e2 == 1\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3e3": {
     "name": "q3e3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2.5\n>>> hidden: True\n>>> # END TEST CONFIG\n>>> # HIDDEN\n>>> assert a3e3 == 4\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4b": {
     "name": "q4b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2.5\n>>> hidden: True\n>>> # END TEST CONFIG\n>>> # HIDDEN\n>>> assert a4b == 'bmi'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4c": {
     "name": "q4c",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2.5\n>>> hidden: True\n>>> # END TEST CONFIG\n>>> # HIDDEN\n>>> assert len(a4c) == 11 and (a4c == np.array(['age','gender','bmi','bp','s1','s2','s3','s4','s5','s6','DiseaseProgression'])).all()\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4d": {
     "name": "q4d",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2.5\n>>> hidden: True\n>>> # END TEST CONFIG\n>>> # HIDDEN\n>>> assert a4d[0] == (442,10) and a4d[1][0] == 442\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4e": {
     "name": "q4e",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2.5\n>>> hidden: True\n>>> # END TEST CONFIG\n>>> # HIDDEN\n>>> assert isclose(a4e,3890.4566,abs_tol=0.02)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4f": {
     "name": "q4f",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2.5\n>>> hidden: True\n>>> # END TEST CONFIG\n>>> # HIDDEN\n>>> assert isclose(a4f,2859.6963,abs_tol=0.02)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4g": {
     "name": "q4g",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2.5\n>>> hidden: True\n>>> # END TEST CONFIG\n>>> # HIDDEN\n>>> assert isclose(a4g,2868.5497,abs_tol=0.02)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4h": {
     "name": "q4h",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2.5\n>>> hidden: True\n>>> # END TEST CONFIG\n>>> # HIDDEN\n>>> assert isclose(a4h,2900.1936,abs_tol=0.02)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4i": {
     "name": "q4i",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2.5\n>>> hidden: True\n>>> # END TEST CONFIG\n>>> # HIDDEN\n>>> assert a4i == 3\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4j": {
     "name": "q4j",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2.5 \n>>> hidden: True\n>>> # END TEST CONFIG\n>>> # HIDDEN\n>>> assert True\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
