{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 08: Classification\n",
    "\n",
    "**Due:** Midnight on March 23 (with a 2-hour grace period)  \n",
    "\n",
    "\n",
    "### Overview\n",
    "\n",
    "In this final homework before starting our course project, we will introduce the essential machine learning paradigm of **classification**. We will work with a well-known Kaggle dataset—the Pima Indians Diabetes dataset—to determine whether an individual has diabetes (1) or not (0). This is a binary classification task.\n",
    "\n",
    "As we’ve discussed in this week’s lessons, the classification workflow is similar to what we’ve done for regression, with a few key differences:\n",
    "- Instead of `RepeatedKFold` we use `RepeatedStratifiedKFold` (read the docs to understand the difference)\n",
    "- We use classification metrics (e.g., accuracy, precision, recall, F1-score) instead of regression metrics--for simplicity we'll just use accuracy in this homework. \n",
    "\n",
    "For this assignment, you’ll build two models and measure their performance using the accuracy metric. \n",
    "1. A **logistic regression** classifier as a baseline.\n",
    "2. One of the **ensemble** classifiers of your choice.\n",
    "\n",
    "Because we’ve already covered much of the workflow in our regression assignments, this homework is intentionally concise and less prescriptive.\n",
    "\n",
    "### Grading\n",
    "\n",
    "There are 5 graded problems, each worth 5 points, for a total of 25 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful imports\n",
    "\n",
    "import os\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import io\n",
    "import zipfile\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold,GridSearchCV\n",
    "from sklearn.ensemble        import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.metrics         import accuracy_score\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from tqdm                    import tqdm\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# globals\n",
    "\n",
    "random_state = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem One:  Load, Explore, and Preprocess the Kaggle Pima Indians Diabetes Dataset \n",
    "\n",
    "In the follow cell(s), \n",
    "- Download the dataset from Kaggle\n",
    "- Perform some simple EDA using `.head()`, `.info()` and `.hist()`\n",
    "    - When using a classification dataset, **always** look to see whether the target is balanced (approximately equal numbers of classes) or not. \n",
    "- Create the feature set `X` and the target set `y` (using `Outcome` as the target)\n",
    "- Scale `X` using `StandardScalar` (since the classification models often prefer this)\n",
    "- Split the dataset into 80% training and 20% testing sets\n",
    "- Verify that the graded answer is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 Graded Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing to do, but you might want to check and make sure this is correct\n",
    "\n",
    "a1 = (X_train.shape,X_test.shape)                          \n",
    "\n",
    "print(f'a1 = {a1}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interlude: Wrapper Functions for Running Classification Models\n",
    "\n",
    "The following cells are adapted from the Week 7 homework in order to use accuracy as the error metric. You can easily modify these\n",
    "if you wish to consider other metrics.  \n",
    "\n",
    "\n",
    "**Note:** `sweep_parameter` sets `X_train` etc. to default values using the global values for `X_train` etc. you created in problem 1.  Should work fine as is, but you can always just ignore the defaults and assign the parameters explicitly. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def run_model(model, X_train, y_train, X_test, y_test, n_repeats=10, n_jobs=-1, **model_params):\n",
    "\n",
    "    # Remove extra key used to store error metric, if it was added to the parameter dictionary\n",
    "    \n",
    "    if 'accuracy_found' in model_params:\n",
    "        model_params = model_params.copy()\n",
    "        model_params.pop('accuracy_found', None)  \n",
    "        \n",
    "    # Instantiate the model if a class is provided\n",
    "    if isinstance(model, type):\n",
    "        model = model(**model_params)\n",
    "    else:                                    \n",
    "        model.set_params(**model_params)    \n",
    "\n",
    "    # Use RepeatedStratifiedKFold for classification to preserve class distribution\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=n_repeats, random_state=42)\n",
    "    \n",
    "    # Perform 5-fold cross-validation using accuracy as the scoring metric\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=n_jobs)\n",
    "    \n",
    "    mean_cv_accuracy = np.mean(cv_scores)\n",
    "    std_cv_accuracy  = np.std(cv_scores)\n",
    "    \n",
    "    # Fit the model on the full training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Compute training and testing accuracy\n",
    "    train_preds    = model.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, train_preds)\n",
    "    test_preds     = model.predict(X_test)\n",
    "    test_accuracy  = accuracy_score(y_test, test_preds)\n",
    "    \n",
    "    return mean_cv_accuracy, std_cv_accuracy, train_accuracy, test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def sweep_parameter(model,\n",
    "                    Parameters,\n",
    "                    param,\n",
    "                    parameter_list,\n",
    "                    X_train          = X_train,                 # The defaults use global parameters, you can override this by simply giving the arguments explicitly\n",
    "                    y_train          = y_train,\n",
    "                    X_test           = X_test,\n",
    "                    y_test           = y_test,\n",
    "                    verbose          = True,\n",
    "                    n_iter_no_change = None,\n",
    "                    delta            = 0.001,\n",
    "                    n_jobs           = -1,\n",
    "                    n_repeats        = 10\n",
    "                   ):\n",
    "\n",
    "    start = time.time()\n",
    "    Parameters = Parameters.copy()  # Avoid modifying the original dictionary\n",
    "    \n",
    "    cv_accuracies, std_cvs, train_accuracies, test_accuracies = [], [], [], []\n",
    "    no_improve_count = 0\n",
    "    best_accuracy = -np.inf  # since higher accuracy is better\n",
    "    \n",
    "    # Run over each value in parameter_list\n",
    "    for p in tqdm(parameter_list, desc=f\"Sweeping {param}\"):\n",
    "        Parameters[param] = p\n",
    "        P_temp = Parameters.copy()\n",
    "        # Remove accuracy_found if present, just in case\n",
    "        P_temp.pop('accuracy_found', None)\n",
    "        \n",
    "        # run_model should return: mean_cv_accuracy, std_cv_accuracy, train_accuracy, test_accuracy\n",
    "        mean_cv_accuracy, std_cv_accuracy, train_accuracy, test_accuracy = run_model(\n",
    "            model=model,\n",
    "            X_train=X_train, y_train=y_train,\n",
    "            X_test=X_test,   y_test=y_test,\n",
    "            n_repeats=n_repeats,\n",
    "            n_jobs=n_jobs,\n",
    "            **P_temp\n",
    "        )\n",
    "        cv_accuracies.append(mean_cv_accuracy)\n",
    "        std_cvs.append(std_cv_accuracy)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "        # Early-stopping logic: maximize accuracy\n",
    "        if mean_cv_accuracy > best_accuracy + delta:\n",
    "            best_accuracy = mean_cv_accuracy\n",
    "            no_improve_count = 0\n",
    "        else:\n",
    "            no_improve_count += 1\n",
    "        \n",
    "        if n_iter_no_change is not None and no_improve_count >= n_iter_no_change:\n",
    "            print(f\"Early stopping: No improvement after {n_iter_no_change} iterations.\")\n",
    "            break\n",
    "    \n",
    "    # Identify best parameter\n",
    "    max_cv_accuracy = max(cv_accuracies)\n",
    "    max_index = cv_accuracies.index(max_cv_accuracy)\n",
    "    best_param = parameter_list[max_index]\n",
    "    Parameters[param] = best_param\n",
    "    Parameters['accuracy_found'] = max_cv_accuracy\n",
    "    \n",
    "    if verbose:\n",
    "        # Prepare for plotting\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8), sharex=True)\n",
    "        \n",
    "        # Use only as many parameter values as computed\n",
    "        partial_param_list = parameter_list[:len(cv_accuracies)]\n",
    "        \n",
    "        # Check if our parameter list is Boolean for proper labeling\n",
    "        is_boolean = all(isinstance(val, bool) for val in partial_param_list)\n",
    "        if is_boolean:\n",
    "            # Convert booleans to integer indices for plotting\n",
    "            x_vals = list(range(len(partial_param_list)))\n",
    "            x_labels = [str(val) for val in partial_param_list]\n",
    "        else:\n",
    "            x_vals = partial_param_list\n",
    "            x_labels = partial_param_list\n",
    "        \n",
    "        # ----- First plot: Accuracy -----\n",
    "        ax1.set_title(f\"Accuracy vs {param}\")\n",
    "        \n",
    "        ax1.plot(x_vals,\n",
    "                 cv_accuracies,\n",
    "                 marker='.', label=\"CV Accuracy\", color='blue')\n",
    "        ax1.plot(x_vals,\n",
    "                 train_accuracies,\n",
    "                 marker='.', label=\"Train Accuracy\", color='green')\n",
    "        ax1.plot(x_vals,\n",
    "                 test_accuracies,\n",
    "                 linestyle='--', label=\"Test Accuracy\", color='orange')\n",
    "        ax1.scatter([x_vals[max_index]],\n",
    "                    [max_cv_accuracy],\n",
    "                    marker='x', label=\"Best CV Accuracy\", color='red')\n",
    "        \n",
    "        ax1.set_ylabel(\"Accuracy\")\n",
    "        ax1.legend()\n",
    "        ax1.grid()\n",
    "        \n",
    "        # ----- Second plot: CV Standard Deviation -----\n",
    "        ax2.set_title(f\"CV Standard Deviation vs {param}\")\n",
    "        ax2.plot(x_vals, std_cvs, marker='.', label=\"CV Accuracy Std\", color='blue')\n",
    "        ax2.set_xlabel(param)\n",
    "        ax2.set_ylabel(\"Standard Deviation\")\n",
    "        ax2.legend()\n",
    "        ax2.grid(alpha=0.5)\n",
    "        \n",
    "        # If using boolean x-values, set custom ticks\n",
    "        if is_boolean:\n",
    "            ax2.set_xticks(x_vals)\n",
    "            ax2.set_xticklabels(x_labels)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        end = time.time()\n",
    "        print(\"Execution Time:\", time.strftime(\"%H:%M:%S\", time.gmtime(end - start)))\n",
    "    \n",
    "    return Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Two: Classification using Logistic Regression (Baseline)  \n",
    "\n",
    "For this problem,\n",
    "- Read the docs for `LogisticRegression`\n",
    "- Run the model with `class_weight = 'balanced'` and `max_iter=1000` using `run_model` or just your own code. \n",
    "- Answer the graded questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code; add as many cells as you need\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.A Graded Answer\n",
    "\n",
    "Provide the mean CV accuracy score of your best model in the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the mean CV accuracy\n",
    "\n",
    "a2a = 0.0                              # Just to get it to run without errors, put your answer here                       \n",
    "\n",
    "print(f'a2a = {a2a:.4f}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.B Graded Answer\n",
    "\n",
    "Provide the test accuracy of your best model in the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the test accuracy\n",
    "\n",
    "a2b = 0.0                               # Just to get it to run without errors, put your answer here                          \n",
    "\n",
    "print(f'a2b = {a2b:.4f}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Three: Classification using Ensemble Methods  \n",
    "\n",
    "For this problem,\n",
    "- Choose one of the ensemble methods for classification (see the first code cell above)\n",
    "- Read about the hyperparameters for the model in the `sklearn` docs\n",
    "- Tune the model for best performance using the wrapper functions and/or grid search as needed\n",
    "- Answer the graded questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.A Graded Answer\n",
    "\n",
    "Provide the mean CV accuracy score of your best model in the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the mean CV accuracy\n",
    "\n",
    "a3a = 0.0                              # Just to get this cell to run without errors, put your answer here                 \n",
    "\n",
    "print(f'a3a = {a3a:.4f}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.B Graded Answer\n",
    "\n",
    "Provide the test accuracy of your best model in the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the test accuracy\n",
    "\n",
    "a3b = 0.0                              # Just to get this cell to run without errors, put your answer here \n",
    "\n",
    "print(f'a3b = {a3b:.4f}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
