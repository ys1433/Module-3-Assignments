{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Milestone One: Gathering your Team, Understanding the Problem,  Exploring the Data\n",
    "\n",
    "## Due: Midnight on March 30 (with 2-hour grace period) and worth 25 points\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### What We Will Do in This Milestone Assignment\n",
    "\n",
    "1. You will convene your team (listed on Blackboard) and fill out the Team Contract (in the Homework Repo), to be submitted to Gradescope.\n",
    "2. You must select a team leader for the purpose of submitting this notebook, after the team collaborates to complete the assignment. The team leader should upload the notebook and then create a group on GS for the group submission.\n",
    "3. At the conclusion of your work on this Milestone, you will complete an Individual Evaluation of your team's work (in the Homework Repo) and upload it *individually* to Gradescope.\n",
    "4. We will follow a simplified version of the **Machine Learning Project Checklist** in Appendix A in our textbook *Hands-On Machine Learning* (pp.779):  \n",
    "\n",
    ">Part 1:\tFrame the problem and look at the big picture  \n",
    "Part 2: Download and perform preliminary exploration of the data  \n",
    "Part 3: Clean the Data: Drop, Impute, and Encode   \n",
    "Part 4: Explore Feature Relationships  \n",
    "Part 5: Investigate Feature Engineering options to better expose the underlying data patterns  \n",
    "\n",
    "### The Dataset\n",
    "\n",
    "All teams will use the same dataset. It is a smaller version of the Zillow housing dataset that was used in the\n",
    "Zillow Million Dollar Prize which ran on Kaggle in 2017 (sorry, the contest is closed, so you can't win any money\n",
    "with this project!).  We will try to predict the assessed tax value (`'taxvaluedollarcnt'`) of the property from a large collection\n",
    "of descriptors. Some features are closely related and some are obviously useless.  There are potential outliers and also quite a few missing values. \n",
    "\n",
    "This is a good example of a dataset which has not been predigested for you on Kaggle, and should give you a good chance to\n",
    "try all the various tools in your toolbox!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Useful Imports\n",
    "# =============================\n",
    "\n",
    "# Standard Libraries\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from itertools import chain, combinations\n",
    "\n",
    "# Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.ticker as mticker  # Optional: Format y-axis labels as dollars\n",
    "\n",
    "# Scikit-learn (Machine Learning)\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, \n",
    "    cross_val_score, \n",
    "    GridSearchCV, \n",
    "    RandomizedSearchCV, \n",
    "    RepeatedKFold\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, f_regression, SelectKBest\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Kaggle and Progress Tracking\n",
    "import kagglehub\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============================\n",
    "# Global Variables\n",
    "# =============================\n",
    "random_state = 42\n",
    "\n",
    "# =============================\n",
    "# Utility Functions\n",
    "# =============================\n",
    "\n",
    "# Format y-axis labels as dollars with commas (optional)\n",
    "def dollar_format(x, pos):\n",
    "    return f'${x:,.0f}'\n",
    "\n",
    "# Convert seconds to HH:MM:SS format\n",
    "def format_hms(seconds):\n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(seconds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelude: Download the Zillow Housing Dataset \n",
    "\n",
    "The code cell below will load the dataset for you.    \n",
    "\n",
    "> **Notice that before downloading, this cell first checks whether the files already exist.** \n",
    "\n",
    "For a detailed description of the dataset features, please refer to  **Appendix 1** below. \n",
    "\n",
    "**Note:** Do **not** perform a train/test split for this milestone (unlike HOML suggests), since you need to do the split **after** any data preparation and feature engineering. You can wait until Milestone 2 to do the split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = \"https://www.cs.bu.edu/fac/snyder/cs505/Data/zillow_dataset.csv\"\n",
    "\n",
    "filename = os.path.basename(urlparse(url).path)\n",
    "\n",
    "if not os.path.exists(filename):\n",
    "    try:\n",
    "        print(\"Downloading the file...\")\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(\"File downloaded successfully.\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading the file: {e}\")\n",
    "else:\n",
    "    print(\"File already exists. Skipping download.\")\n",
    "\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Frame the problem and look at the big picture [3 pts]\n",
    "\n",
    "This part is a bit vague, since this project is not taking place in an actual business, but for the sake of exercizing all the steps, **pretend** that you are working at Zillow as a data analyst and are given this dataset and asked to\n",
    "- Analyze and understand the data; \n",
    "- Create a regression model;\n",
    "- Give a presentation to the marketing team about your results.  \n",
    "\n",
    "#### **1 Discussion:** \n",
    "\n",
    "AFTER doing your EDA, come back and answer each of the following 3 questions in a *concise and informative paragraph between the lines;* you may wish to use your own business or home-buying experience, or to do some online research about the issues before you propose your ideas. (Don't stress about this, but *humor your professor and give it your best shot!*)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1:**  What is the objective of this project in business terms?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2:**  How will your solution be used?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3:**  How should success (or failure) be measured?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Download and perform preliminary exploration of the data [4 pts]\n",
    "\n",
    "### Part 2.A: Load the data into a dataframe and study each feature/column and its characteristics:\n",
    "- Name\n",
    "- Type (categorical, int/float, text, etc.)\n",
    "- Apparent usefulness for the task\n",
    "- Approximate % of missing values\n",
    "- How many unique values\n",
    "\n",
    "**Note:** The **target** is the last column `'taxvaluedollarcnt'` -- pay particular attention to this during the EDA process. \n",
    "  \n",
    "Hint: Just use `.head()`, `.info()`, and `.nunique()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.A Discussion:** Answer the following questions.\n",
    "\n",
    "**2.A.1:**  Which features are categorical?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**2.A.2:**  Are there any features which appear at first glance to be **useless** for the business purpose of this project and should be deleted?  Give examples and describe your reasoning briefly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**2.A.3:**  Are there any features which appear to be **useless** because of the percentage of missing values?  If so, give an example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**2.A.4:**  Are there any features which appear to be **useless** because of the number of unique values?  If so, give an example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.B: Exploratory Data Analysis (EDA) -- Feature-Level Visualization  \n",
    "\n",
    "- To get an overview, generate histograms for all features using `df.hist()`  (Hint: increase the figsize and set the layout to `(-1,m)` to get  `m` columns and as many rows as necessary.)\n",
    "- Generate individual visualizations for the **target and three (3)** other interesting-looking features in the dataset (i.e., a total of 4):  \n",
    "    - Use appropriate plot types (e.g., histograms and boxplots for numerical features, bar plots for categorical features) to understand distributions and identify potential outliers for these three.\n",
    "    - Use as many code cells as you need, and give comments describing what each cell does.\n",
    "    - Answer the discussion question posed (you should choose 3 features for which you can say something interesting in the discussion).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.B Discussion:** Describe in a paragraph what you learned in your detailed examination of the features you explored:\n",
    "- What is the distribution (normal, exponential, etc.) if any?\n",
    "- Any problems (e.g., outliers, any odd characteristics)?\n",
    "- Anything else interesting? Why did you choose it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3:  Clean the Data: Drop, Impute, and Encode [6 pts]\n",
    "\n",
    "\n",
    "\n",
    "**Important Notes:**\n",
    "- You should review your Homework 4 before doing this section!\n",
    "- Create new names for modified data at each stage to avoid problems with global variables.\n",
    "- Whenever possible, write functions for all data transformations you apply, for these reasons:\n",
    "    - So you can easily prepare the data the next time you get a fresh dataset\n",
    "    - So you can apply these transformations in future projects\n",
    "    - To clean and prepare new data instances once your solution is live\n",
    "    - To make it easy to treat your preparation choices as hyperparameters\n",
    "    - [To apply the same transformations to your test set if train/test split already done -- not applicable here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.A: Drop features you judge to be unsuitable for the regression task\n",
    "\n",
    "Your call, based on any research you can do to understand the feature (hopefully IRL you would have a domain expert to help with this, but do your best).   \n",
    "\n",
    "Note: Do not drop features because of too many missing values, that's the next task! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.A Discussion:** Justify in a paragraph your decisions about which features to drop. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.B: Drop **features** with \"too many\" null values\n",
    "\n",
    "Your code in the next cell(s). Make a judgement call about what \"too many\" means and briefly describe your reasoning in the discussion.   \n",
    "\n",
    "Note: \"Too many\" may depend on what the non-null values look like, be sure to investigate carefully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.B Discussion:** In a paragraph, explain your decision about which features were dropped\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.C: Drop Problematic **samples** \n",
    "\n",
    "There could be several reasons why you might want to drop a sample:\n",
    "- It has  \"too many\" null values \n",
    "- It has a null value in the target\n",
    "- It contains outliers, especially in the target\n",
    "\n",
    "\n",
    "\n",
    "Your code in the next cell(s). Make a judgement call about which samples should be dropped and briefly describe your reasoning in the discussion.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **3.C Discussion:** In a short paragraph, explain your decision about which samples were dropped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.D: Impute for the remaining missing values\n",
    "\n",
    "Review the methods for imputation in **Appendix 2** and choose how you will impute the remainder of the missing values. Note:\n",
    "- Consider whether different methods are justified for different features.\n",
    "- In the next cells, apply your imputation methods to the dataset so that no null values remain after this step.\n",
    "- Answer the discussion question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.D Discussion:**  Describe in a paragraph your decisions about which methods you used to impute missing values in the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.E: Encode the Categorical Features (if any)\n",
    "\n",
    "You may not have any categorical features. If you do, encode them in the next step. No discussion is necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4:  Investigate Feature Relationships  [6 pts]\n",
    "\n",
    "In this part, we will investigate the feature relationships as a way of understanding the data.  In the next part, we'll investigate potential feature engineering opportunities.\n",
    "\n",
    "**Note:**  We won't be committing to any changes to the data until Milestone 2, as our choice of transformations will very much depend on the model we're building. But investigating these aspects of the data is an essential step in the first stages of our project. \n",
    "\n",
    "### Part 4.A:\n",
    "\n",
    "   - Compute and analyze pairwise correlations using a correlation matrix.\n",
    "   - Compute the F-statistic for all features for a better view of the relationships (displaying them in a bar chart would be useful as well). \n",
    "   - Identify features with strong correlations or notable relationships that may impact model performance.\n",
    "   - Investigate forward and backward feature selection\n",
    "        - Run these algorithms to investigate possible feature selection (don't commit to any selections yet)\n",
    "\n",
    "Your code below, in multiple cells with descriptive comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.A Discussion:**  Describe in a paragraph what you see in the feature relationships and correlations.\n",
    "\n",
    "Pay particular attention to especially interesting and/or strongly correlated feature relationships. \n",
    " How do the different methods for seeing relationships compare? Do they agree or disagree?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4.B:  2-Dimensional Visualizations for Interesting Patterns  \n",
    "   - Select three (3) pairs of features that exhibit meaningful relationships based on your previous analysis. \n",
    "   - Create 2D scatter plots or density plots to explore interactions between these features.  \n",
    "   - Provide brief interpretations of any observed patterns or trends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.B Discussion:** Provide brief interpretations of any observed patterns or trends.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5:  Feature Engineering: Investigate various transformations to better expose the underlying data patterns to machine learning algorithms. [6 pts]\n",
    "\n",
    "**Important Notes:**  \n",
    "- This last part is a bit open ended, since there is a huge variety of feature engineering techniques, most of which won't be useful for your particular dataset. \n",
    "- Understand that you can't evaluate the final usefulness of these transformations\n",
    "until you choose a model, and  models may respond differently to various transformations or obviate some transformations (e.g., ensemble methods already do feature selection). \n",
    "- Therefore, write your transformations as functions or otherwise be prepared\n",
    "to choose later on which transformations may be necessary. \n",
    "\n",
    "**Investigate feature engineering, where appropriate:**\n",
    "\n",
    "- Feature scaling: standardize or normalize features as necessary\n",
    "- Decompose features (e.g., categorical into One-Hot feature sequence, date/time into two features data and time, etc.).\n",
    "- Add promising transformations of features\n",
    "    - Exponential $\\exp(x_i)$ or logarithmic $\\log(x_j)$\n",
    "    - Polynomial features  ( $x_i^2$, $x_i - x_j$), products ($x_i*x_j$), or ratios ($x_i/x_j$)\n",
    "\n",
    "**ToDo:**\n",
    "- Pick at least three transformations to try.\n",
    "- Try each one and evaluate its effect using correlations or F-scores or a feature selection algorithm.\n",
    "- Answer the discussion question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5 Discussion:** Describe in a paragraph why you chose these transformations and what you observed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Appendix 1: Features of the Zillow Dataset**  \n",
    "\n",
    "0. **parcelid**: Unique identifier for the property parcel.  \n",
    "1. **airconditioningtypeid**: Identifier for the type of air conditioning installed.  \n",
    "2. **architecturalstyletypeid**: Identifier for the architectural style of the property.  \n",
    "3. **basementsqft**: Square footage of the basement.  \n",
    "4. **bathroomcnt**: Number of bathrooms.  \n",
    "5. **bedroomcnt**: Number of bedrooms.  \n",
    "6. **buildingclasstypeid**: Identifier for the building framing type (e.g., wood frame, steel frame).  \n",
    "7. **buildingqualitytypeid**: Numeric value indicating the quality of the building (higher values often indicate better quality).  \n",
    "8. **calculatedbathnbr**: Calculated number of bathrooms, including fractional bathrooms.  \n",
    "9. **decktypeid**: Identifier for the type of deck.  \n",
    "10. **finishedfloor1squarefeet**: Square footage of the finished area on the first floor.  \n",
    "11. **calculatedfinishedsquarefeet**: Total finished living area square footage.  \n",
    "12. **finishedsquarefeet12**: Finished living area square footage.  \n",
    "13. **finishedsquarefeet13**: Perimeter living area square footage.  \n",
    "14. **finishedsquarefeet15**: Total area.  \n",
    "15. **finishedsquarefeet50**: Square footage of the finished area on the upper floors.  \n",
    "16. **finishedsquarefeet6**: Base unfinished and finished area square footage.  \n",
    "17. **fips**: Federal Information Processing Standards code, uniquely identifying counties and county equivalents.  \n",
    "18. **fireplacecnt**: Number of fireplaces.  \n",
    "19. **fullbathcnt**: Number of full bathrooms.  \n",
    "20. **garagecarcnt**: Number of cars that can fit in the garage.  \n",
    "21. **garagetotalsqft**: Total square footage of the garage.  \n",
    "22. **hashottuborspa**: Indicates if the property has a hot tub or spa.  \n",
    "23. **heatingorsystemtypeid**: Identifier for the type of heating system.  \n",
    "24. **latitude**: Latitude coordinate of the property.  \n",
    "25. **longitude**: Longitude coordinate of the property.  \n",
    "26. **lotsizesquarefeet**: Lot size in square feet.  \n",
    "27. **poolcnt**: Number of pools on the property.  \n",
    "28. **poolsizesum**: Total square footage of all pools.  \n",
    "29. **pooltypeid10**: Identifier for spa or hot tub.  \n",
    "30. **pooltypeid2**: Identifier for pool with spa or hot tub.  \n",
    "31. **pooltypeid7**: Identifier for pool without hot tub or spa.  \n",
    "32. **propertycountylandusecode**: County land use code for the property.  \n",
    "33. **propertylandusetypeid**: Identifier for the property land use type.  \n",
    "34. **propertyzoningdesc**: Description of the property's zoning.  \n",
    "35. **rawcensustractandblock**: Unprocessed census tract and block identifier.  \n",
    "36. **regionidcity**: Identifier for the city.  \n",
    "37. **regionidcounty**: Identifier for the county.  \n",
    "38. **regionidneighborhood**: Identifier for the neighborhood.  \n",
    "39. **regionidzip**: Identifier for the ZIP code.  \n",
    "40. **roomcnt**: Total number of rooms.  \n",
    "41. **storytypeid**: Identifier for the type of stories in the building (e.g., basement, attic).  \n",
    "42. **threequarterbathnbr**: Number of 3/4 bathrooms (typically includes a shower but no tub).  \n",
    "43. **typeconstructiontypeid**: Identifier for the type of construction (e.g., frame, masonry).  \n",
    "44. **unitcnt**: Number of units in the building (e.g., for multi-family properties).  \n",
    "45. **yardbuildingsqft17**: Square footage of the 17th yard building (e.g., shed).  \n",
    "46. **yardbuildingsqft26**: Square footage of the 26th yard building.  \n",
    "47. **yearbuilt**: Year the property was built.  \n",
    "48. **numberofstories**: Number of stories in the building.  \n",
    "49. **fireplaceflag**: Indicates if the property has a fireplace.  \n",
    "50. **assessmentyear**: Year the property was assessed.  \n",
    "51. **taxdelinquencyflag**: Indicates whether the property’s taxes are delinquent. Often “Y” if taxes are past due; otherwise null/empty.  \n",
    "52. **taxdelinquencyyear**: The year in which the property’s taxes became delinquent.  \n",
    "53. **censustractandblock**: A combined identifier for the property’s census tract and block group (part of the U.S. Census geographic hierarchy).  \n",
    "54. **taxvaluedollarcnt**: Total assessed value of the property (land plus structure) in dollars.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 2: Summary of Basic Imputation Methods\n",
    "Imputation depends on the data type and context. Below are common techniques for handling missing values.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Simple Imputation (Basic Methods)**\n",
    "| Method | Best For | Code Example | Pros | Cons |\n",
    "|--------|---------|--------------|------|------|\n",
    "| **Drop Missing Values** | Few missing values (<5% of data) | `df.dropna()` | Quick and easy | Can remove valuable data |\n",
    "| **Mean Imputation** | Normally distributed numerical data | `df.fillna(df.mean())` | Preserves mean; simple | Distorts variance, weak for skewed data |\n",
    "| **Median Imputation** | Skewed numerical data | `df.fillna(df.median())` | Robust to outliers | May not capture patterns |\n",
    "| **Mode Imputation** | Categorical features | `df.fillna(df.mode().iloc[0])` | Keeps most common category | Can introduce bias |\n",
    "| **Constant Value (e.g., 0)** | Special cases (e.g., unknown numerical data) | `df.fillna(0)` | Simple and interpretable | Can mislead model |\n",
    "| **\"Unknown\" Category Imputation** (**New Addition**) | Categorical features with missing values | `df.fillna('Unknown')` | Keeps all rows, prevents data loss | May introduce artificial category |\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Statistical & Advanced Imputation**\n",
    "| Method | Best For | Code Example | Pros | Cons |\n",
    "|--------|---------|--------------|------|------|\n",
    "| **Interpolation** | Time series, ordered data | `df.interpolate(method='linear')` | Preserves trends | May not work for non-continuous data |\n",
    "| **K-Nearest Neighbors (KNN)** | Small datasets, patterns in features | `KNNImputer(n_neighbors=5).fit_transform(df)` | Uses similar observations | Computationally expensive |\n",
    "| **Multivariate Imputation (MICE)** | Complex relationships between variables | `IterativeImputer().fit_transform(df)` | Captures relationships | Slower than mean/median |\n",
    "| **Regression Imputation** | When missing values depend on other variables | Train regression model to predict missing values | More accurate than mean/median | Risk of overfitting |\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use \"Unknown\" Category for Categorical Imputation**\n",
    "✅ **Good for:**\n",
    "- Categorical features where missing values may indicate meaningful differences.  \n",
    "- Customer data (e.g., missing survey responses → \"No Response\").  \n",
    "- Product categories where missing could be a separate group.  \n",
    "\n",
    "❌ **Avoid if:**\n",
    "- The missing category does **not** have a meaningful interpretation.\n",
    "- The model might learn spurious patterns from an artificial category.\n",
    "\n",
    "---\n",
    "\n",
    "### **Which Method to Choose?**\n",
    "| Scenario | Best Method |\n",
    "|----------|------------|\n",
    "| **Few missing values (<5%)** | Drop NaNs (`df.dropna()`) |\n",
    "| **Numerical & normal distribution** | Mean (`df.fillna(df.mean())`) |\n",
    "| **Numerical & skewed distribution** | Median (`df.fillna(df.median())`) |\n",
    "| **Categorical features** | Mode (`df.fillna(df.mode().iloc[0])`) |\n",
    "| **Categorical with possible meaning in missingness** | \"Unknown\" Category (`df.fillna('Unknown')`) |\n",
    "| **Small dataset with patterns** | KNN Imputer (`KNNImputer()`) |\n",
    "| **Complex relationships between features** | MICE / Iterative Imputer |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
