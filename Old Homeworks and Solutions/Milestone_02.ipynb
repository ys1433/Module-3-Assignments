{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Milestone Two: Modeling and Feature Engineering\n",
    "\n",
    "### Due: Midnight on April 13 (with 2-hour grace period) and worth 25 points\n",
    "\n",
    "### Overview\n",
    "\n",
    "This milestone builds on your work from Milestone 1. You will:\n",
    "\n",
    "1. Evaluate baseline models using default settings.\n",
    "2. Engineer new features and re-evaluate models.\n",
    "3. Use feature selection techniques to find promising subsets.\n",
    "4. Select the top 3 models and fine-tune them for optimal performance.\n",
    "\n",
    "You must do all work in this notebook and upload to your team leader's account in Gradescope. There is no\n",
    "Individual Assessment for this Milestone. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# Useful Imports: Add more as needed\n",
    "# ===================================\n",
    "\n",
    "# Standard Libraries\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from itertools import chain, combinations\n",
    "\n",
    "# Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.ticker as mticker  # Optional: Format y-axis labels as dollars\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn (Machine Learning)\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, \n",
    "    cross_val_score, \n",
    "    GridSearchCV, \n",
    "    RandomizedSearchCV, \n",
    "    RepeatedKFold\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, f_regression, SelectKBest\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Progress Tracking\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============================\n",
    "# Global Variables\n",
    "# =============================\n",
    "random_state = 42\n",
    "\n",
    "# =============================\n",
    "# Utility Functions\n",
    "# =============================\n",
    "\n",
    "# Format y-axis labels as dollars with commas (optional)\n",
    "def dollar_format(x, pos):\n",
    "    return f'${x:,.0f}'\n",
    "\n",
    "# Convert seconds to HH:MM:SS format\n",
    "def format_hms(seconds):\n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(seconds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelude: Load your Preprocessed Dataset from Milestone 1\n",
    "\n",
    "In Milestone 1, you handled missing values, encoded categorical features, and explored your data. Before you begin this milestone, you’ll need to load that cleaned dataset and prepare it for modeling.\n",
    "\n",
    "Here’s what to do:\n",
    "\n",
    "1. Return to your Milestone 1 notebook and rerun your code through Part 3, where your dataset was fully cleaned (assume it’s called `df_cleaned`).\n",
    "\n",
    "2. **Save** the cleaned dataset to a file by running:\n",
    "\n",
    ">   df_cleaned.to_csv(\"zillow_cleaned.csv\", index=False)\n",
    "\n",
    "3. Switch to this notebook and **load** the saved data:\n",
    "\n",
    ">   df = pd.read_csv(\"zillow_cleaned.csv\")\n",
    "\n",
    "4. Create a **train/test split** using `train_test_split`.  \n",
    "   \n",
    "6. **Standardize** the features (but not the target!) using **only the training data.** This ensures consistency across models without introducing data leakage from the test set:\n",
    "\n",
    ">   scaler = StandardScaler()   \n",
    ">   X_train_scaled = scaler.fit_transform(X_train)    \n",
    "  \n",
    "**Notes:** \n",
    "\n",
    "- You will not use the testing set during this milestone — it’s reserved for final evaluation later.\n",
    "- You will have to redo the scaling step when you introduce new features (which have to be scaled as well).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add as many code cells as you need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Baseline Modeling [3 pts]\n",
    "\n",
    "Apply the following regression models to the scaled training dataset using **default parameters**:\n",
    "\n",
    "- Linear Regression\n",
    "- Ridge Regression\n",
    "- Lasso Regression\n",
    "- Decision Tree Regression\n",
    "- Bagging\n",
    "- Random Forest\n",
    "- Gradient Boosting Trees\n",
    "\n",
    "For each model:\n",
    "- Use **repeated cross-validation** (e.g., 5 folds, 5 repeats).\n",
    "- Report the **mean and standard deviation of CV RMSE Score** across all folds in a table. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add as many code cells as you need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Discussion [2 pts]\n",
    "\n",
    "In a paragraph or well-organized set of bullet points, briefly compare and discuss:\n",
    "\n",
    "  - Which models perform best overall?\n",
    "  - Which are most stable (lowest std)?\n",
    "  - Any signs of overfitting or underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Your text here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Feature Engineering [3 pts]\n",
    "\n",
    "Consider **at least three new features** based on your Milestone 1, Part 5. Examples include:\n",
    "- Polynomial terms\n",
    "- Log or interaction terms\n",
    "- Groupings or transformations of categorical features\n",
    "\n",
    "Add these features to `X_train` and then:\n",
    "- Scale using `StandardScaler` \n",
    "- Re-run all models listed above (using default settings again).\n",
    "- Report updated RMSE scores (mean and std) across repeated CV in a table. \n",
    "\n",
    "**Note:**  Recall that this will require creating a new version of the dataset, so effectively you may be running \"polynomial regression\" using `LinearRegression`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add as many code cells as you need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Discussion [2 pts]\n",
    "\n",
    "Reflect on the impact of your new features:\n",
    "\n",
    "- Did any models show notable improvement in performance?\n",
    "\n",
    "- Which new features seemed to help — and in which models?\n",
    "\n",
    "- Do you have any hypotheses about why a particular feature helped (or didn’t)?\n",
    "\n",
    "- Were there any unexpected results?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Your text here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Feature Selection [3 pts]\n",
    "\n",
    "Using the full set of features (original + engineered):\n",
    "- Apply **feature selection** methods to investigate whether you can improve performance.\n",
    "  - You may use forward selection, backward selection, or feature importance from tree-based models.\n",
    "- For each model, identify the **best-performing subset of features**.\n",
    "- Re-run each model using only those features.\n",
    "- Report updated RMSE scores (mean and std) across repeated CV in a table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Discussion [2 pts]\n",
    "\n",
    "Analyze the effect of feature selection on your models:\n",
    "\n",
    "- Did performance improve for any models after reducing the number of features?\n",
    "\n",
    "- Which features were consistently retained across models?\n",
    "\n",
    "- Were any of your newly engineered features selected as important?\n",
    "\n",
    "- How did feature selection differ between linear and tree-based models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Your text here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Fine-Tuning Your Top 3 Models [6 pts]\n",
    "\n",
    "In this final phase of Milestone 2, you’ll select and refine your **three most promising models and their corresponding data pipelines** based on everything you've done so far.\n",
    "\n",
    "1. Choose the top 3 models based on performance and interpretability from earlier parts.\n",
    "2. For each model:\n",
    "   - Perform hyperparameter tuning using `sweep_parameters`, `GridSearchCV`, `RandomizedSearchCV`, or other techniques from previous homeworks. \n",
    "   - Experiment with different versions of your feature engineering and preprocessing — treat these as additional tunable components.\n",
    "3. Report the mean and standard deviation of CV RMSE score for each model in a summary table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add as many code cells as you need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Discussion [4 pts]\n",
    "\n",
    "Reflect on your tuning process and final results:\n",
    "\n",
    "- What was your tuning strategy for each model? Why did you choose those hyperparameters?\n",
    "- Did you find that certain types of preprocessing or feature engineering worked better with specific models?\n",
    "- Provide a ranking of your three models and explain your reasoning — not just based on RMSE, but also interpretability, training time, or generalizability.\n",
    "- Conclude by considering whether this workflow has produced the results you expected. Typically, you would repeat steps 2 - 4 and also reconsider the choices you made in Milestone 1 when cleaning the dataset, until reaching the point of diminishing returns; do you think that would that have helped here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Your text here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
