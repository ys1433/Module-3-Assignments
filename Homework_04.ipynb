{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 04:  Null Values, Categorical Features, and Cross Validation\n",
    "\n",
    "In this homework, we are going to add three **tools to your toolbox** which will be essential when you work with real datasets:\n",
    "1. What do we do with null-values?\n",
    "2. How do we deal with non-numeric features?\n",
    "3. What validation strategy provides the best estimate of the final testing score?\n",
    "\n",
    "For (1), we'll explore several ways of dealing with null values:\n",
    "- Removing columns with too many null values,\n",
    "- Imputing values for missing categorical labels using the \"most frequent\" category strategy, and\n",
    "- Imputing values for missing numeric values using the median. \n",
    "\n",
    "\n",
    "For (2), we'll use ordinal encoding to replace categorical labels with floats.\n",
    "\n",
    "For (3), we'll try three different cross-validation strategies:\n",
    "\n",
    "- 5-Fold CV,\n",
    "- Repeated 5-Fold CV, and\n",
    "- Leave one out CV, \n",
    "\n",
    "and see which comes closest to estimating the final testing MSE. \n",
    "\n",
    "\n",
    "#### Grading: There are eight (8) answers to provide, each worth 6 points.  (You get 2 points for free.)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful imports\n",
    "\n",
    "import os\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold, LeaveOneOut\n",
    "from sklearn.linear_model    import LinearRegression\n",
    "from sklearn.preprocessing   import OrdinalEncoder, OneHotEncoder  \n",
    "from sklearn.impute          import SimpleImputer\n",
    "from sklearn.metrics         import mean_squared_error, r2_score\n",
    "from tqdm                    import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Ames Housing Dataset\n",
    "\n",
    "For a description of the features of this dataset, see the **Appendix**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the latest version of the dataset\n",
    "path = kagglehub.dataset_download(\"shashanknecrothapa/ames-housing-dataset\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Construct the full path to the CSV file (update the file name if necessary)\n",
    "csv_file = os.path.join(path, \"AmesHousing.csv\")\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>526301100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>526350040</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>526351010</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>526353030</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>93.0</td>\n",
       "      <td>11160</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>527105010</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>189900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "0      1  526301100           20        RL         141.0     31770   Pave   \n",
       "1      2  526350040           20        RH          80.0     11622   Pave   \n",
       "2      3  526351010           20        RL          81.0     14267   Pave   \n",
       "3      4  526353030           20        RL          93.0     11160   Pave   \n",
       "4      5  527105010           60        RL          74.0     13830   Pave   \n",
       "\n",
       "  Alley Lot Shape Land Contour  ... Pool Area Pool QC  Fence Misc Feature  \\\n",
       "0   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n",
       "1   NaN       Reg          Lvl  ...         0     NaN  MnPrv          NaN   \n",
       "2   NaN       IR1          Lvl  ...         0     NaN    NaN         Gar2   \n",
       "3   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n",
       "4   NaN       IR1          Lvl  ...         0     NaN  MnPrv          NaN   \n",
       "\n",
       "  Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n",
       "0        0       5    2010       WD           Normal     215000  \n",
       "1        0       6    2010       WD           Normal     105000  \n",
       "2    12500       6    2010       WD           Normal     172000  \n",
       "3        0       4    2010       WD           Normal     244000  \n",
       "4        0       3    2010       WD           Normal     189900  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this to see the listing of features\n",
    "\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this to see the feature histograms\n",
    "\n",
    "# print(\"Feature Histograms\")\n",
    "# df.hist(figsize=(15, 13), bins=30)  # Adjust figure size and number of bins\n",
    "# plt.tight_layout()  # Adjust spacing to prevent overlap\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "First, let's remove the features that are clearly not useful for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Lot Config</th>\n",
       "      <th>...</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>93.0</td>\n",
       "      <td>11160</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>189900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MS SubClass MS Zoning  Lot Frontage  Lot Area Street Alley Lot Shape  \\\n",
       "0           20        RL         141.0     31770   Pave   NaN       IR1   \n",
       "1           20        RH          80.0     11622   Pave   NaN       Reg   \n",
       "2           20        RL          81.0     14267   Pave   NaN       IR1   \n",
       "3           20        RL          93.0     11160   Pave   NaN       Reg   \n",
       "4           60        RL          74.0     13830   Pave   NaN       IR1   \n",
       "\n",
       "  Land Contour Utilities Lot Config  ... Pool Area Pool QC  Fence  \\\n",
       "0          Lvl    AllPub     Corner  ...         0     NaN    NaN   \n",
       "1          Lvl    AllPub     Inside  ...         0     NaN  MnPrv   \n",
       "2          Lvl    AllPub     Corner  ...         0     NaN    NaN   \n",
       "3          Lvl    AllPub     Corner  ...         0     NaN    NaN   \n",
       "4          Lvl    AllPub     Inside  ...         0     NaN  MnPrv   \n",
       "\n",
       "  Misc Feature Misc Val Mo Sold  Yr Sold  Sale Type  Sale Condition  SalePrice  \n",
       "0          NaN        0       5     2010        WD           Normal     215000  \n",
       "1          NaN        0       6     2010        WD           Normal     105000  \n",
       "2         Gar2    12500       6     2010        WD           Normal     172000  \n",
       "3          NaN        0       4     2010        WD           Normal     244000  \n",
       "4          NaN        0       3     2010        WD           Normal     189900  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df.drop(columns=['Order','PID'])\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem One: Dealing with Null Values\n",
    "\n",
    "There are basically two strategies for dealing with missing (null or `NaN`) values:\n",
    "- Get them out of your dataset by **removing** features and/or samples containing too many nulls.\n",
    "- **Impute** values by replacing nulls with the mean, median, or other \"neutral\" value computed from the feature.\n",
    "\n",
    "**Note:** It is also possible to impute values using more advanced techniques such as mode imputation, forward/backward fill, or predictive modeling (e.g., KNN or regression-based imputation). These techniques might be useful when you start to work on your projecct. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First we will explore how many null values occur in each feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will list how many nulls occur in which features\n",
    "\n",
    "def show_null_counts_features(df):\n",
    "    # Count the nulls and calculate the %\n",
    "    count_nulls = df.isnull().sum()\n",
    "    df_nulls = (df.isnull().mean() * 100).round(2)\n",
    "    \n",
    "    # Determine if the column is numeric or non-numeric\n",
    "    feature_types = df.dtypes.apply(lambda x: 'Numeric' if np.issubdtype(x, np.number) else 'Categorical')\n",
    "    \n",
    "    # Filter out the columns with missing values and sort them in descending order\n",
    "    missing_data = pd.DataFrame({\n",
    "        'Feature': count_nulls[count_nulls > 0].index,\n",
    "        '# Null Values': count_nulls[count_nulls > 0].values, \n",
    "        'Null %': df_nulls[df_nulls > 0].values,\n",
    "        'Type': feature_types[count_nulls > 0].values\n",
    "    }).sort_values(by='Null %', ascending=False)\n",
    "    \n",
    "    print(f'The dataset contains {len(df)} samples.\\n')\n",
    "\n",
    "    if (len(missing_data) == 0):\n",
    "        print(\"There are no null values in the dataset!\")\n",
    "    else:\n",
    "        # Print null value stats\n",
    "        print('Feature Name    # Nulls      Null %    Type')\n",
    "        print('------------    -------      ------    ----')\n",
    "        for index, row in missing_data.iterrows():\n",
    "            print(f\"{row['Feature']:<15} {row['# Null Values']:<12} {row['Null %']:.2f}%   {row['Type']}\")\n",
    "\n",
    "show_null_counts_features(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A\n",
    "\n",
    "Clearly, some of these features are not very informative! Let's drop the worst offenders!\n",
    "\n",
    "**Fill in your code after the comments below to drop any features with more than `max_nulls` null values.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_nulls = 500      # We will drop any features with more than max_nulls missing values\n",
    "\n",
    "# Count null values per column\n",
    "\n",
    "\n",
    "\n",
    "# Filter out columns where null count exceeds max_nulls\n",
    "\n",
    "\n",
    "\n",
    "# Drop the columns\n",
    "\n",
    "\n",
    "\n",
    "# Uncomment to verify they were removed\n",
    "\n",
    "# show_null_counts_features(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1a = Ellipsis\n"
     ]
    }
   ],
   "source": [
    "# Set this variable to the number of columns that were dropped\n",
    "\n",
    "a1a = ...\n",
    "\n",
    "print(f\"a1a = {a1a}\")                                   # Don't delete or change this line, it is needed by the auto-grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B:  Feature Transformations for Imputing Null Values\n",
    "\n",
    "Now let's perform the following feature transformations:\n",
    "\n",
    "- For categorical features, we'll replace null values with the most frequent category in that column\n",
    "- For numeric features, we'll replace nulls with the median for that column\n",
    "\n",
    "\n",
    "This is very simple to do with a couple of lines of Python, but naturally we want to use `sklearn` functions whenever we can, so we'll use ` SimpleImputer`.\n",
    "\n",
    "**Go read the doc page for `SimpleImputer` before proceeding.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Categorical Features using the Most Frequent Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell you see how easy it is to examine the categories. **Take a moment and explore several of the categorical features.**  In this dataset, most of them are skewed, with a clear \"most favorite\" category. \n",
    "(If the feature values are not skewed, then you could change these to a new category \"Unknown\".)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Garage Qual\n",
       "TA     2615\n",
       "NaN     159\n",
       "Fa      124\n",
       "Gd       24\n",
       "Po        5\n",
       "Ex        3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['Garage Qual'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, let's get lists of the two types of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical and numeric features\n",
    "\n",
    "categorical_features = df_clean.select_dtypes(exclude=['number']).columns.tolist()\n",
    "numeric_features     = df_clean.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# Print results if you want\n",
    "# print(\"Categorical Features:\", categorical_features)\n",
    "# print(\"Numeric Features:\", numeric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now you must impute all the categorical features using `SimpleImputer` with the `most_frequent` strategy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First make a copy of the cleaned dataset, call it df_imputed\n",
    "\n",
    "\n",
    "# Impute categorical columns (using most frequent category)\n",
    "\n",
    "\n",
    "\n",
    "# Verify: only numeric features should appear\n",
    "\n",
    "# show_null_counts_features(df_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1b = Ellipsis\n"
     ]
    }
   ],
   "source": [
    "# Set this variable to the number of occurrences of the category 'TA' in the feature 'Garage Qual'\n",
    "# It should have increased from before the imputation, because Nan values were changed to 'TA'\n",
    "\n",
    "a1b = ...     \n",
    "\n",
    "print(f\"a1b = {a1b}\")                                   # Don't delete or change this line, it is needed by the auto-grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C:  Imputing Numeric Features using the Median\n",
    "\n",
    "Now you must \"simply impute\" values for the numeric features using the `median` strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute numeric columns (using the median)\n",
    "\n",
    "\n",
    "# Verify: There should be no null values\n",
    "\n",
    "# show_null_counts_features(df_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing to do here:   Answer should be 0 \n",
    "\n",
    "a1c = df_imputed.isnull().any(axis=1).sum()      # count number of rows with any missing values\n",
    "\n",
    "print(f\"a1c = {a1c}\")                            # Don't delete or change this line, it is needed by the auto-grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D:   Ordinal encoding the categorical features with OrdinalEncoder\n",
    "\n",
    "The simplest option in dealing with categorical values is to represent them by integers 0, 1, 2, etc.\n",
    "\n",
    "**Before proceeding, read the doc page on `sklearn`'s `OrdinalEncoder`.**\n",
    "\n",
    "Follow the comments to perform this feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put df_imputed in the form X, y\n",
    "\n",
    "\n",
    "\n",
    "# Initialize OrdinalEncoder\n",
    "\n",
    "\n",
    "# Fit and transform categorical columns\n",
    "\n",
    "\n",
    "# Convert back to DataFrame to retain column names \n",
    "\n",
    "\n",
    "# Verify\n",
    "\n",
    "# X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing to do here:   Answer should show categories encoded as floats for 'Lot Shape'\n",
    "\n",
    "a1d = X['Lot Shape'].unique()                      \n",
    "\n",
    "print(f\"a1d = {a1d}\")                            # Don't delete or change this line, it is needed by the auto-grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Two:  Train and Test a Regression Model with Cross-Validation\n",
    "\n",
    "In this problem, we will perform a regression on the Ames Housing Dataset using several different cross-validation\n",
    "strategies, comparing the cross-validation score for each with the final testing MSE, to see which provides the best\n",
    "estimate of the final test score, and hence of the model's ability to generalize. \n",
    "\n",
    "\n",
    "We shall compare each of the following cross-validation MSEs with the final test MSE score:\n",
    "\n",
    "- 5-Fold Cross-Validation (default)\n",
    "- Repeated 5-Fold Cross-Validation (repeated 100 times)\n",
    "- Leave-One-Out Cross Validation\n",
    "\n",
    "**Note:  Set `n_jobs = -1` when doing cross validation to take advantage of parallelism in your environment.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: 5-Fold Cross-Validation\n",
    "\n",
    "For this part\n",
    "- Create a train-test split with `test_size=0.2` \n",
    "- Create a linear model and perform K-fold cross-validation with K = 5 and using `cross_val_score` with `scoring='neg_mean_squared_error'` (remember to take the mean of the CV scores and negate the result, since scoring uses a negative MSE). \n",
    "- Report (print out) the\n",
    "    - CV score (negated mean of MSE measurements over all K folds)\n",
    "    - Test MSE\n",
    "\n",
    "\n",
    "Use `random_state = 42` for all experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign to this variable the Test MSE \n",
    "\n",
    "a2a = ...               \n",
    "\n",
    "print(f\"a2a = {a2a:.4f}\")                            # Don't delete or change this line, it is needed by the auto-grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Perform Repeated 5-Fold Cross Validation\n",
    "\n",
    "Read the doc page on `sklearn`'s `RepeatedKFold` for cross validation; repeat the CV calculation with K = 5 and `n_repeats=100`\n",
    "and report the CV score (negated mean of MSE measurements over all 100*K folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign to this variable the mean CV score for the repeated K-fold experiment \n",
    "# Note: if your CV score is negative, go back and read the instructions for Part A again!\n",
    "\n",
    "a2b = ...               \n",
    "\n",
    "print(f\"a2b = {a2b:.4f}\")                            # Don't delete or change this line, it is needed by the auto-grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C: Perform Leave One Out Cross Validation\n",
    "\n",
    "This is simply a matter of setting `cv=LeaveOneOut()`. Run the same experiment and report the CV score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign to this variable the mean CV score for the leave-one-out experiment \n",
    "\n",
    "a2c = ...               \n",
    "\n",
    "print(f\"a2c = {a2c:.4f}\")                            # Don't delete or change this line, it is needed by the auto-grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D\n",
    "\n",
    "Now, in order to help interpret the results, print out a table of the **square roots** of each of the CV scores and the final test score; we can then see the result in the same units (dollars) as the target, instead of the units of the MSE (dollars squared). \n",
    "\n",
    "Hint: Here is an example of how to print out values as currency:\n",
    "\n",
    "    cost = 23512.23\n",
    "    print(f\"cost: ${cost:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2d = Ellipsis\n"
     ]
    }
   ],
   "source": [
    "# Assign to this variable the letter of the CV strategy whose RMSE came closest to the actual test score\n",
    "\n",
    "a2d = ...                      # Should be 'A' = 5-fold CV; 'B' = Repeated 5-Fold CV; or 'C' = LOO CV                   \n",
    "\n",
    "print(f\"a2d = {a2d}\")         # Don't delete or change this line, it is needed by the auto-grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional\n",
    "\n",
    "- Try K-Fold CV with various K\n",
    "- Try `RepeatedKFold` with various K and various `n_repeated`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Explanation of Features in Ames Housing Dataset\n",
    "\n",
    "### **Identification**\n",
    "- `PID` → Parcel Identification Number (unique identifier for each property)\n",
    "- `Order` → Row number (used for indexing, not a feature)\n",
    "\n",
    "---\n",
    "\n",
    "### **Sale Information**\n",
    "- `SalePrice` → The final selling price of the house in USD (**Target variable**)\n",
    "- `Mo Sold` → Month the house was sold (1 = January, ..., 12 = December)\n",
    "- `Yr Sold` → Year the house was sold\n",
    "- `Sale Type` → Type of sale (e.g., **WD** = Warranty Deed, **New** = Newly Built)\n",
    "- `Sale Condition` → Condition of the sale (e.g., **Normal**, **Abnormal**, **Partial** for incomplete homes)\n",
    "\n",
    "---\n",
    "\n",
    "### **General Property Information**\n",
    "- `MS SubClass` → Type of dwelling (e.g., **20 = 1-story**, **60 = 2-story**, **120 = Townhouse**)\n",
    "- `MS Zoning` → Zoning classification (e.g., **RL = Residential Low Density**, **C = Commercial**)\n",
    "- `Lot Frontage` → Linear feet of street connected to property\n",
    "- `Lot Area` → Total size of the lot in square feet\n",
    "- `Neighborhood` → Physical locations within Ames (e.g., **CollgCr = College Creek**)\n",
    "- `Condition 1` / `Condition 2` → Proximity to roads or railroads (e.g., **Norm = Normal**, **PosN = Near Park**)\n",
    "\n",
    "---\n",
    "\n",
    "### **Building & House Design**\n",
    "- `Bldg Type` → Type of dwelling (e.g., **1Fam = Single Family**, **Twnhs = Townhouse**)\n",
    "- `House Style` → Style of the house (e.g., **1Story = One Story**, **2Story = Two Story**, **SplitFoyer**)\n",
    "- `Overall Qual` → Overall quality of materials (scale: **1 = Very Poor** to **10 = Excellent**)\n",
    "- `Overall Cond` → Overall condition of the house (scale: **1 = Very Poor** to **10 = Excellent**)\n",
    "\n",
    "---\n",
    "\n",
    "### **Year Built & Remodel**\n",
    "- `Year Built` → Original construction year\n",
    "- `Year Remod/Add` → Year of last remodel or addition\n",
    "\n",
    "---\n",
    "\n",
    "### **Exterior Features**\n",
    "- `Exterior 1st` / `Exterior 2nd` → Exterior covering material (e.g., **VinylSd = Vinyl Siding**, **HdBoard = Hardboard**)\n",
    "- `Mas Vnr Type` → Masonry veneer type (e.g., **BrkFace = Brick Face**, **None = No Veneer**)\n",
    "- `Mas Vnr Area` → Area of masonry veneer in square feet\n",
    "\n",
    "---\n",
    "\n",
    "### **Basement Features**\n",
    "- `Bsmt Qual` → Basement height (e.g., **Ex = Excellent**, **TA = Typical**, **Po = Poor**)\n",
    "- `Bsmt Cond` → General condition of the basement\n",
    "- `Bsmt Exposure` → Walkout or garden level basement?\n",
    "- `BsmtFin Type 1` / `BsmtFin SF 1` → Primary finished area in basement (e.g., **GLQ = Good Living Quarters**)\n",
    "- `BsmtFin Type 2` / `BsmtFin SF 2` → Secondary finished area\n",
    "- `Bsmt Unf SF` → Unfinished square feet in basement\n",
    "- `Total Bsmt SF` → Total square footage of basement\n",
    "\n",
    "---\n",
    "\n",
    "### **Utilities & HVAC**\n",
    "- `Heating` → Type of heating system (e.g., **GasA = Gas Forced Air**, **OthW = Hot Water Heating**)\n",
    "- `Heating QC` → Quality of heating system (e.g., **Ex = Excellent**, **Fa = Fair**)\n",
    "- `Central Air` → **Y = Yes**, **N = No**\n",
    "- `Electrical` → Electrical system (e.g., **SBrkr = Standard Breaker**, **FuseA = Fuse Box**)\n",
    "\n",
    "---\n",
    "\n",
    "### **Above Ground Living Area**\n",
    "- `1st Flr SF` → First-floor square footage\n",
    "- `2nd Flr SF` → Second-floor square footage\n",
    "- `Gr Liv Area` → Total **above-ground** living area in square feet\n",
    "- `Low Qual Fin SF` → Low-quality finished square feet (e.g., unfinished rooms)\n",
    "\n",
    "---\n",
    "\n",
    "### **Bathrooms & Bedrooms**\n",
    "- `Full Bath` → Full bathrooms above ground\n",
    "- `Half Bath` → Half bathrooms above ground\n",
    "- `Bsmt Full Bath` → Full bathrooms in basement\n",
    "- `Bsmt Half Bath` → Half bathrooms in basement\n",
    "- `Bedroom AbvGr` → Number of bedrooms above ground\n",
    "- `Kitchen AbvGr` → Number of kitchens above ground\n",
    "- `Kitchen Qual` → Kitchen quality (**Ex = Excellent**, **Fa = Fair**)\n",
    "\n",
    "---\n",
    "\n",
    "### **Garage Features**\n",
    "- `Garage Type` → Type of garage (e.g., **Attchd = Attached**, **Detchd = Detached**)\n",
    "- `Garage Yr Blt` → Year garage was built\n",
    "- `Garage Finish` → Interior finish of garage\n",
    "- `Garage Cars` → Size of garage in car capacity\n",
    "- `Garage Area` → Garage size in square feet\n",
    "\n",
    "---\n",
    "\n",
    "### **Additional Features**\n",
    "- `Fireplaces` → Number of fireplaces\n",
    "- `Fireplace Qu` → Fireplace quality\n",
    "- `Paved Drive` → Paved driveway? (**Y = Yes, P = Partial, N = No**)\n",
    "- `Wood Deck SF` → Square footage of wood deck\n",
    "- `Open Porch SF` → Square footage of open porch\n",
    "- `Enclosed Porch` → Square footage of enclosed porch\n",
    "- `Screen Porch` → Square footage of screened porch\n",
    "- `Pool Area` → Pool area in square feet\n",
    "- `Misc Val` → Miscellaneous features (e.g., shed value)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
